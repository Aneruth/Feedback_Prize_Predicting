{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# Package for preprocssing\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Package for train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model package for classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the text\n",
    "def lowerText(aText):\n",
    "    return aText.lower()\n",
    "\n",
    "data['discourse_text'] = data['discourse_text'].apply(lowerText)\n",
    "\n",
    "# Remove puntuation and numerical values\n",
    "def removePunctuation(aText):\n",
    "    return re.sub(r'[^\\w\\s]', '', aText)\n",
    "\n",
    "data['discourse_text'] = data['discourse_text'].apply(removePunctuation)\n",
    "\n",
    "# Remove stopwords\n",
    "stpWrds = set(stopwords.words('english'))\n",
    "\n",
    "def removeStpWrds(aText):\n",
    "    return ' '.join([words for words in aText.split(' ') if words not in stpWrds])\n",
    "\n",
    "data['discourse_text'] = data['discourse_text'].apply(removeStpWrds)\n",
    "\n",
    "# Stemming the words\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemWords(aText):\n",
    "    return ' '.join([stemmer.stem(words) for words in aText.split(' ')])\n",
    "\n",
    "data['discourse_text'] = data['discourse_text'].apply(stemWords)\n",
    "\n",
    "# Removing all the emoji if present\n",
    "def remove_emoji(aText):\n",
    "    return emoji.get_emoji_regexp().sub(u'', aText)\n",
    "\n",
    "data['discourse_text'] = data['discourse_text'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsettig the dataset\n",
    "df = data[['discourse_text','discourse_type','discourse_effectiveness']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder() # Encoder for type of discourse_type\n",
    "\n",
    "fe = LabelEncoder() # Encoder for type of discourse_effectiveness\n",
    "\n",
    "df['discourse_type'] = le.fit_transform(df['discourse_type'])\n",
    "\n",
    "df['discourse_effectiveness'] = fe.fit_transform(df['discourse_effectiveness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the encoding values in a dictionary format\n",
    "type_mapping = dict(zip(range(len(le.classes_)), le.classes_))\n",
    "class_mapping = dict(zip(range(len(fe.classes_)), fe.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58421128, 1.3140682 , 1.89647168])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalising the weights since we have different weights for three classes\n",
    "class_weight = compute_class_weight('balanced',classes = np.unique(df['discourse_effectiveness']), y = df['discourse_effectiveness'])\n",
    "\n",
    "class_weight # Pass this weight to model classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "t = Tokenizer(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_on_texts(df.discourse_text)\n",
    "feature = t.texts_to_matrix(df.discourse_text, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(df.discourse_effectiveness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=30,\n",
       "                       min_samples_split=5, n_estimators=400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=30,\n",
       "                       min_samples_split=5, n_estimators=400)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=30,\n",
       "                       min_samples_split=5, n_estimators=400)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced',n_estimators=400,bootstrap= True,max_depth= 30,max_features='sqrt',min_samples_leaf=1,min_samples_split=5)\n",
    "\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "rf_prediction = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for Random Forest before hyper parameter tunning is \n",
      "[[3552 1026 1653]\n",
      " [ 985 1632  177]\n",
      " [ 860  113 1032]]\n",
      "\n",
      " Classification report for Random Forest before hyper parameter tunning is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.57      0.61      6231\n",
      "           1       0.59      0.58      0.59      2794\n",
      "           2       0.36      0.51      0.42      2005\n",
      "\n",
      "    accuracy                           0.56     11030\n",
      "   macro avg       0.54      0.56      0.54     11030\n",
      "weighted avg       0.59      0.56      0.57     11030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(f'The confusion matrix for Random Forest before hyper parameter tunning is \\n{confusion_matrix(y_test,rf_prediction)}')\n",
    "\n",
    "print(f'\\n Classification report for Random Forest before hyper parameter tunning is:\\n{classification_report(y_test,rf_prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test['discourse_text']\n",
    "test_data = test_data.apply(lowerText)\n",
    "test_data = test_data.apply(removePunctuation)\n",
    "test_data = test_data.apply(removeStpWrds)\n",
    "test_data = test_data.apply(stemWords)\n",
    "test_data = test_data.apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = t.texts_to_matrix(test_data, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34216201, 0.57879827, 0.07903972],\n",
       "       [0.45271629, 0.41772717, 0.12955653],\n",
       "       [0.39150505, 0.28157212, 0.32692282],\n",
       "       [0.3796475 , 0.32499964, 0.29535285],\n",
       "       [0.31973675, 0.42123411, 0.25902914],\n",
       "       [0.30581966, 0.61462021, 0.07956014],\n",
       "       [0.27796269, 0.63513985, 0.08689746],\n",
       "       [0.32457466, 0.45505374, 0.2203716 ],\n",
       "       [0.29732987, 0.56009527, 0.14257485],\n",
       "       [0.24861406, 0.68819317, 0.06319277]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict_proba(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "251297b380f6eb723ab860aa521a088c65106abc9b0b2e7065cf1ab8bd44f57b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
